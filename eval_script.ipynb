{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n",
      "Setup complete âœ… (8 CPUs, 8.0 GB RAM, 198.9/228.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/test/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 3311.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [20:03<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.845      0.573       0.68      0.383\n",
      "                 biker        209        341      0.709      0.601       0.65      0.351\n",
      "                   car       2585      12853      0.847      0.788      0.843       0.56\n",
      "            pedestrian        744       2253      0.749      0.532      0.629      0.309\n",
      "          trafficLight        301        482      0.816      0.797       0.85      0.501\n",
      "    trafficLight-Green        389       1117      0.812      0.599      0.681      0.303\n",
      "trafficLight-GreenLeft         40         54      0.814      0.485      0.554      0.263\n",
      "      trafficLight-Red        518       1441      0.918      0.696      0.803       0.46\n",
      "  trafficLight-RedLeft        240        337      0.881      0.718      0.795      0.437\n",
      "   trafficLight-Yellow         26         54      0.931      0.315      0.472      0.209\n",
      "trafficLight-YellowLeft          3          3          1          0      0.372      0.239\n",
      "                 truck        530        732      0.813      0.773      0.834       0.58\n",
      "Speed: 0.6ms preprocess, 398.2ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/modified_test/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 3569.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/modified_test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [22:05<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.536      0.186      0.203     0.0981\n",
      "                 biker        209        341      0.323      0.196      0.174      0.076\n",
      "                   car       2585      12853      0.665      0.365      0.411      0.232\n",
      "            pedestrian        744       2253      0.385      0.174      0.164     0.0696\n",
      "          trafficLight        301        482      0.565      0.253      0.277      0.139\n",
      "    trafficLight-Green        389       1117      0.552      0.211      0.223     0.0894\n",
      "trafficLight-GreenLeft         40         54     0.0938     0.0741     0.0274     0.0104\n",
      "      trafficLight-Red        518       1441      0.698      0.267      0.321       0.16\n",
      "  trafficLight-RedLeft        240        337      0.724      0.199      0.251      0.114\n",
      "   trafficLight-Yellow         26         54      0.374     0.0741     0.0798     0.0346\n",
      "trafficLight-YellowLeft          3          3          1          0     0.0502    0.00502\n",
      "                 truck        530        732      0.519      0.232      0.255      0.148\n",
      "Speed: 1.1ms preprocess, 437.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "modified_metrics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/mud/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 4388.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/mud/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [20:17<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.744      0.343      0.385      0.203\n",
      "                 biker        209        341      0.636      0.358      0.395      0.189\n",
      "                   car       2585      12853      0.749      0.547      0.589      0.353\n",
      "            pedestrian        744       2253      0.616       0.36      0.394      0.179\n",
      "          trafficLight        301        482      0.811      0.427      0.521      0.285\n",
      "    trafficLight-Green        389       1117       0.71      0.364      0.398      0.171\n",
      "trafficLight-GreenLeft         40         54      0.652      0.185      0.214     0.0997\n",
      "      trafficLight-Red        518       1441      0.856      0.437      0.526       0.28\n",
      "  trafficLight-RedLeft        240        337       0.81      0.401      0.469      0.251\n",
      "   trafficLight-Yellow         26         54      0.697      0.185      0.214      0.096\n",
      "trafficLight-YellowLeft          3          3          1          0          0          0\n",
      "                 truck        530        732      0.647      0.507      0.516       0.33\n",
      "Speed: 0.7ms preprocess, 402.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mud_metrtics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/tint/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 4034.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/tint/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [19:59<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.722      0.393      0.458      0.253\n",
      "                 biker        209        341      0.756      0.354      0.459      0.241\n",
      "                   car       2585      12853      0.832      0.632      0.708      0.452\n",
      "            pedestrian        744       2253      0.585      0.385      0.413      0.195\n",
      "          trafficLight        301        482      0.688      0.593      0.648       0.36\n",
      "    trafficLight-Green        389       1117      0.734      0.389      0.485      0.208\n",
      "trafficLight-GreenLeft         40         54      0.269      0.315      0.168     0.0844\n",
      "      trafficLight-Red        518       1441      0.843      0.557      0.656      0.356\n",
      "  trafficLight-RedLeft        240        337      0.842      0.484      0.593      0.315\n",
      "   trafficLight-Yellow         26         54      0.593       0.13       0.17     0.0871\n",
      "trafficLight-YellowLeft          3          3          1          0      0.171      0.102\n",
      "                 truck        530        732      0.799      0.483      0.566      0.383\n",
      "Speed: 0.6ms preprocess, 396.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tint_metrtics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/chromatic_aberration/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 3952.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/chromatic_aberration/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [14:16<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.596      0.331      0.351      0.173\n",
      "                 biker        209        341       0.33       0.46      0.369      0.173\n",
      "                   car       2585      12853      0.813      0.566      0.678        0.4\n",
      "            pedestrian        744       2253      0.486      0.333      0.351      0.147\n",
      "          trafficLight        301        482      0.598      0.463      0.483      0.232\n",
      "    trafficLight-Green        389       1117      0.517      0.347       0.36      0.132\n",
      "trafficLight-GreenLeft         40         54      0.262      0.111       0.12     0.0462\n",
      "      trafficLight-Red        518       1441      0.614      0.371      0.412      0.174\n",
      "  trafficLight-RedLeft        240        337      0.574      0.374       0.38      0.165\n",
      "   trafficLight-Yellow         26         54      0.672     0.0741      0.104     0.0484\n",
      "trafficLight-YellowLeft          3          3          1          0     0.0115    0.00802\n",
      "                 truck        530        732      0.691      0.543      0.595      0.384\n",
      "Speed: 0.5ms preprocess, 282.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "aberration_metrics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/scanline/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 6261.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/scanline/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [13:55<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.741      0.458      0.547      0.295\n",
      "                 biker        209        341      0.708      0.416      0.481      0.247\n",
      "                   car       2585      12853      0.779      0.764      0.805      0.508\n",
      "            pedestrian        744       2253      0.648      0.431      0.496      0.237\n",
      "          trafficLight        301        482      0.744      0.645      0.719      0.384\n",
      "    trafficLight-Green        389       1117      0.715      0.515      0.561       0.24\n",
      "trafficLight-GreenLeft         40         54      0.525      0.278        0.3      0.142\n",
      "      trafficLight-Red        518       1441      0.877      0.597      0.721       0.38\n",
      "  trafficLight-RedLeft        240        337      0.869      0.551      0.659       0.34\n",
      "   trafficLight-Yellow         26         54      0.599      0.204      0.265      0.123\n",
      "trafficLight-YellowLeft          3          3          1          0      0.338      0.203\n",
      "                 truck        530        732      0.685      0.633      0.677      0.436\n",
      "Speed: 0.4ms preprocess, 276.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "scanline_metrics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/crack/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 5130.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/crack/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [14:49<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.738       0.46      0.546      0.294\n",
      "                 biker        209        341      0.439       0.53      0.502      0.252\n",
      "                   car       2585      12853      0.753      0.743      0.784      0.484\n",
      "            pedestrian        744       2253      0.627      0.457      0.506      0.236\n",
      "          trafficLight        301        482      0.778      0.618      0.712      0.403\n",
      "    trafficLight-Green        389       1117      0.746      0.519      0.586      0.243\n",
      "trafficLight-GreenLeft         40         54      0.541      0.218      0.272      0.132\n",
      "      trafficLight-Red        518       1441      0.823      0.624      0.709      0.371\n",
      "  trafficLight-RedLeft        240        337      0.806      0.496      0.604      0.295\n",
      "   trafficLight-Yellow         26         54      0.871       0.25      0.327      0.152\n",
      "trafficLight-YellowLeft          3          3          1          0       0.34      0.238\n",
      "                 truck        530        732       0.73      0.605      0.662      0.425\n",
      "Speed: 0.4ms preprocess, 294.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "crack_metrics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/sensor_blooming/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 3914.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/sensor_blooming/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [20:45<00:00,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.821      0.555      0.671       0.37\n",
      "                 biker        209        341      0.687      0.595      0.645      0.342\n",
      "                   car       2585      12853      0.843      0.786      0.839      0.556\n",
      "            pedestrian        744       2253      0.728      0.541       0.62      0.302\n",
      "          trafficLight        301        482      0.817      0.793      0.842      0.482\n",
      "    trafficLight-Green        389       1117      0.813      0.561      0.654      0.284\n",
      "trafficLight-GreenLeft         40         54      0.769      0.444      0.532      0.226\n",
      "      trafficLight-Red        518       1441      0.906      0.664      0.778      0.438\n",
      "  trafficLight-RedLeft        240        337      0.864      0.681       0.76      0.408\n",
      "   trafficLight-Yellow         26         54      0.816      0.259      0.381      0.174\n",
      "trafficLight-YellowLeft          3          3          1          0      0.502      0.286\n",
      "                 truck        530        732      0.786       0.78       0.83      0.573\n",
      "Speed: 0.8ms preprocess, 411.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "bloom_metrics = model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n",
      "YOLO11s summary (fused): 238 layers, 9,417,057 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/mud/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 3924.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/mud/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [13:49<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.776        0.5      0.595       0.32\n",
      "                 biker        209        341      0.662      0.507      0.564      0.294\n",
      "                   car       2585      12853      0.818      0.761      0.814      0.524\n",
      "            pedestrian        744       2253      0.676      0.459      0.544      0.258\n",
      "          trafficLight        301        482      0.699      0.734      0.766      0.416\n",
      "    trafficLight-Green        389       1117      0.754      0.512      0.579      0.239\n",
      "trafficLight-GreenLeft         40         54       0.59       0.37      0.385      0.166\n",
      "      trafficLight-Red        518       1441      0.874      0.666      0.768       0.41\n",
      "  trafficLight-RedLeft        240        337      0.807      0.617      0.713        0.4\n",
      "   trafficLight-Yellow         26         54      0.893      0.148       0.31      0.135\n",
      "trafficLight-YellowLeft          3          3          1          0      0.337      0.169\n",
      "                 truck        530        732      0.763      0.725      0.766      0.511\n",
      "Speed: 0.5ms preprocess, 274.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "mud_model = YOLO(\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/best_mud.pt\")\n",
    "\n",
    "mud_eval_metrics = mud_model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.13.2 torch-2.6.0 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/test/labels... 2980 images, 336 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2980/2980 [00:00<00:00, 6808.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 187/187 [14:48<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2980      19667      0.823      0.542      0.644      0.351\n",
      "                 biker        209        341      0.734      0.566      0.637      0.332\n",
      "                   car       2585      12853      0.844      0.779      0.834      0.547\n",
      "            pedestrian        744       2253      0.739       0.49      0.596      0.286\n",
      "          trafficLight        301        482      0.752      0.766      0.803      0.439\n",
      "    trafficLight-Green        389       1117      0.777      0.564       0.64      0.271\n",
      "trafficLight-GreenLeft         40         54      0.697      0.469      0.475      0.219\n",
      "      trafficLight-Red        518       1441      0.896      0.696      0.798       0.43\n",
      "  trafficLight-RedLeft        240        337       0.86      0.677      0.775      0.426\n",
      "   trafficLight-Yellow         26         54      0.946      0.204      0.393      0.161\n",
      "trafficLight-YellowLeft          3          3          1          0      0.338      0.203\n",
      "                 truck        530        732      0.806      0.757      0.799      0.544\n",
      "Speed: 0.6ms preprocess, 293.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val26\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mud_metrics_baseline = mud_model.val(data=\"/Users/tomaszfrelek/Downloads/seminar_project/partitioned_data/data.yaml\", split=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
